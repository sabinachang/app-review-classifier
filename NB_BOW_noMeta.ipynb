{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NB-BOW-noMeta.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "j63oZOMQHOvj"
      },
      "source": [
        "import json\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import chi2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "\n",
        "s = set()\n",
        "def load_file(file_path, cur_data):\n",
        "\n",
        "  with open(file_path) as json_file:\n",
        "    raw_data = json.load(json_file)\n",
        "    return convert_data(raw_data,cur_data)\n",
        "\n",
        "def convert_data(raw_data,cur_data):\n",
        "  data = cur_data\n",
        "\n",
        "  for elem in raw_data:\n",
        "    if elem['reviewId'] in s:\n",
        "      continue\n",
        "    else:\n",
        "      new = \"\"\n",
        "      if elem['title']:\n",
        "        new = elem[\"stopwords_removal_lemmatization\"]+ elem['title']\n",
        "      else: \n",
        "        new = elem[\"stopwords_removal_lemmatization\"]\n",
        "      data.append([new, elem[\"label\"]])\n",
        "\n",
        "      s.add(elem['reviewId'])\n",
        "      \n",
        "  return data\n",
        "\n",
        "def convert_label(df, labels):\n",
        "\n",
        "  df['label_code'] = df['label']\n",
        "\n",
        "  df = df.replace({'label_code':labels})\n",
        "  return df\n",
        "\n",
        "def get_combined_df(file_paths, labels):\n",
        "  data = []\n",
        "  for path in file_paths:\n",
        "    data = load_file(path, data)\n",
        "  \n",
        "  s.clear()\n",
        "\n",
        "  # Remove spaces and punctuation in lemma \n",
        "  df = pd.DataFrame(data, columns = ['lemma', 'label'])\n",
        "  \n",
        "  df['lemma'] = df['lemma'].str.replace(\"\\r\", \" \")\n",
        "  df['lemma'] = df['lemma'].str.replace(\"\\n\", \" \")\n",
        "  df['lemma'] = df['lemma'].str.replace(\"  \", \" \")\n",
        "  df['lemma'] = df['lemma'].str.replace('\"', '')\n",
        "  df['lemma'] = df['lemma'].str.lower()\n",
        "\n",
        "  punctuation_signs = list(\"?:!.,;\")\n",
        "  for punct_sign in punctuation_signs:\n",
        "    df['lemma'] = df['lemma'].str.replace(punct_sign, '')\n",
        "\n",
        "  df =  convert_label(df,labels)\n",
        "  count_class_0, count_class_1 = df.label_code.value_counts()\n",
        "  df_class_0 = df[df['label_code'] == 0]\n",
        "  df_class_1 = df[df['label_code'] == 1]\n",
        "  df_class_0_under = df_class_0.sample(count_class_1)\n",
        "  df_test_under = pd.concat([df_class_0_under,df_class_1], axis=0)\n",
        "\n",
        "  return df_test_under\n",
        "\n",
        "\n",
        "def apply_tfidf(X_train, x_test):\n",
        "  # apply tfidf to lemma to create feature vector\n",
        "  ngram_range = (1,2)\n",
        "  max_features = 400 \n",
        "  tfidf = TfidfVectorizer(encoding='utf-8',\n",
        "                      ngram_range=ngram_range,\n",
        "                      max_features=max_features,\n",
        "                      min_df=1,\n",
        "                      max_df=1.0,\n",
        "                      norm='l2',\n",
        "                      sublinear_tf=True)\n",
        "  f_train = tfidf.fit_transform(X_train['lemma'])\n",
        "  f_test = tfidf.transform(x_test['lemma'])\n",
        "  feature_train = pd.DataFrame(f_train.toarray(), columns=tfidf.get_feature_names())\n",
        "\n",
        "  feature_test = pd.DataFrame(f_test.toarray(), columns=tfidf.get_feature_names())\n",
        "\n",
        "  feature_train.fillna(0.0,inplace=True)\n",
        "  feature_test.fillna(0.0, inplace=True)\n",
        "\n",
        "  return feature_train, feature_test                "
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdfHYHwpjOSY"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def train_nb_model(feature_train, y_train, feature_test, y_test):\n",
        "\n",
        "  model = MultinomialNB()\n",
        "\n",
        "  model.fit(feature_train, y_train)\n",
        "\n",
        "\n",
        "  print(\"The bug testing metrics is: \")\n",
        "  print(\"accuracy \" + str(accuracy_score(y_test, model.predict(feature_test))))\n",
        "  print(\"f1 \" + str(f1_score(y_test, model.predict(feature_test))))\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcAq-WT-Qvyf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "931bcc10-8269-42ac-81b9-6f08719ecf61"
      },
      "source": [
        "# bug classifier data\n",
        "df = get_combined_df([\"Bug_tt.json\", \"Feature_tt.json\", \"Rating_tt.json\", \"UserExperience_tt.json\"],\n",
        "                     {\n",
        "                        'Bug': 1,\n",
        "                        'Not_Bug': 0,\n",
        "                        'Not_Feature': 0,\n",
        "                        'Feature': 0,\n",
        "                        'Rating': 0,\n",
        "                        'Not_Rating': 0,\n",
        "                        'UserExperience': 0,\n",
        "                        'Not_UserExperience': 0,\n",
        "                      })\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[['lemma']],\n",
        "                                                    df['label_code'],\n",
        "                                                    test_size=0.15,\n",
        "                                                    random_state=42)\n",
        "feature_train, feature_test = apply_tfidf(X_train, X_test)\n",
        "print(\"Bug classifier\")\n",
        "train_nb_model(feature_train, y_train, feature_test, y_test)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bug classifier\n",
            "The bug testing metrics is: \n",
            "accuracy 0.7431192660550459\n",
            "f1 0.7307692307692307\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIYwZ_tw8JZi",
        "outputId": "32f4688e-cdfd-497e-ca1e-889b1b8be235"
      },
      "source": [
        "# feature classifier data\n",
        "df = get_combined_df([\"Feature_tt.json\", \"Rating_tt.json\", \"Bug_tt.json\", \"UserExperience_tt.json\"],\n",
        "                     {\n",
        "                        'Bug': 0,\n",
        "                        'Not_Bug': 0,\n",
        "                        'Not_Feature': 0,\n",
        "                        'Feature': 1,\n",
        "                        'Rating': 0,\n",
        "                        'Not_Rating': 0,\n",
        "                        'UserExperience': 0,\n",
        "                        'Not_UserExperience': 0,\n",
        "                      })\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[['lemma']],\n",
        "                                                    df['label_code'],\n",
        "                                                    test_size=0.15,\n",
        "                                                    random_state=42)\n",
        "feature_train, feature_test = apply_tfidf(X_train, X_test)\n",
        "print(\"Feature classifier\")\n",
        "train_nb_model(feature_train, y_train, feature_test, y_test)\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature classifier\n",
            "The bug testing metrics is: \n",
            "accuracy 0.7272727272727273\n",
            "f1 0.7142857142857143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKEbvbso8-VH",
        "outputId": "fe5effc0-0df4-4e8b-acfd-9455432334ec"
      },
      "source": [
        "# rating classifier data\n",
        "df = get_combined_df([\"Rating_tt.json\", \"Bug_tt.json\", \"Feature_tt.json\",\"UserExperience_tt.json\"],\n",
        "                     {\n",
        "                        'Bug': 0,\n",
        "                        'Not_Bug': 0,\n",
        "                        'Not_Feature': 0,\n",
        "                        'Feature': 0,\n",
        "                        'Rating': 1,\n",
        "                        'Not_Rating': 0,\n",
        "                        'UserExperience': 0,\n",
        "                        'Not_UserExperience': 0,\n",
        "                      })\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[['lemma']],\n",
        "                                                    df['label_code'],\n",
        "                                                    test_size=0.15,\n",
        "                                                    random_state=42)\n",
        "feature_train, feature_test = apply_tfidf(X_train, X_test)\n",
        "print(\"Rating classifier\")\n",
        "train_nb_model(feature_train, y_train, feature_test, y_test)\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rating classifier\n",
            "The bug testing metrics is: \n",
            "accuracy 0.6454545454545455\n",
            "f1 0.6213592233009709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxCOBY7MYpIW",
        "outputId": "de6a506e-e4a6-4ab4-88af-6a68e0012294"
      },
      "source": [
        "# user experience classifier data\n",
        "df = get_combined_df([\"UserExperience_tt.json\", \"Bug_tt.json\", \"Feature_tt.json\",\"Rating_tt.json\"],\n",
        "                     {\n",
        "                        'Bug': 0,\n",
        "                        'Not_Bug': 0,\n",
        "                        'Not_Feature': 0,\n",
        "                        'Feature': 0,\n",
        "                        'Rating': 0,\n",
        "                        'Not_Rating': 0,\n",
        "                        'UserExperience': 1,\n",
        "                        'Not_UserExperience': 0,\n",
        "                      })\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[['lemma']],\n",
        "                                                    df['label_code'],\n",
        "                                                    test_size=0.15,\n",
        "                                                    random_state=42)\n",
        "feature_train, feature_test = apply_tfidf(X_train, X_test)\n",
        "print(\"UserExperience classifier\")\n",
        "train_nb_model(feature_train, y_train, feature_test, y_test)\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UserExperience classifier\n",
            "The bug testing metrics is: \n",
            "accuracy 0.6605504587155964\n",
            "f1 0.6782608695652174\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}