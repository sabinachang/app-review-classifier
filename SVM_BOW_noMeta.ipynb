{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM-BOW-noMeta.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un3w8zhOetGp"
      },
      "source": [
        "import json\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import chi2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "\n",
        "s = set()\n",
        "def load_file(file_path, cur_data):\n",
        "\n",
        "  with open(file_path) as json_file:\n",
        "    raw_data = json.load(json_file)\n",
        "    return convert_data(raw_data,cur_data)\n",
        "\n",
        "def convert_data(raw_data,cur_data):\n",
        "  data = cur_data\n",
        "\n",
        "  for elem in raw_data:\n",
        "    if elem['reviewId'] in s:\n",
        "      continue\n",
        "    else:\n",
        "      new = \"\"\n",
        "      if elem['title']:\n",
        "        new = elem[\"stopwords_removal_lemmatization\"]+ elem['title']\n",
        "      else: \n",
        "        new = elem[\"stopwords_removal_lemmatization\"]\n",
        "      data.append([new, elem[\"label\"]])\n",
        "      s.add(elem['reviewId'])\n",
        "      \n",
        "  return data\n",
        "\n",
        "def convert_label(df, labels):\n",
        "\n",
        "  df['label_code'] = df['label']\n",
        "\n",
        "  df = df.replace({'label_code':labels})\n",
        "  return df\n",
        "\n",
        "\n",
        "def get_combined_df(file_paths, labels):\n",
        "  data = []\n",
        "  for path in file_paths:\n",
        "    data = load_file(path, data)\n",
        "  \n",
        "  s.clear()\n",
        "\n",
        "  # Remove spaces and punctuation in lemma \n",
        "  df = pd.DataFrame(data, columns = ['lemma', 'label'])\n",
        "  \n",
        "  df['lemma'] = df['lemma'].str.replace(\"\\r\", \" \")\n",
        "  df['lemma'] = df['lemma'].str.replace(\"\\n\", \" \")\n",
        "  df['lemma'] = df['lemma'].str.replace(\"  \", \" \")\n",
        "  df['lemma'] = df['lemma'].str.replace('\"', '')\n",
        "  df['lemma'] = df['lemma'].str.lower()\n",
        "\n",
        "  punctuation_signs = list(\"?:!.,;\")\n",
        "  for punct_sign in punctuation_signs:\n",
        "    df['lemma'] = df['lemma'].str.replace(punct_sign, '')\n",
        "\n",
        "  df =  convert_label(df,labels)\n",
        "  count_class_0, count_class_1 = df.label_code.value_counts()\n",
        "  df_class_0 = df[df['label_code'] == 0]\n",
        "  df_class_1 = df[df['label_code'] == 1]\n",
        "  df_class_0_under = df_class_0.sample(count_class_1)\n",
        "  df_test_under = pd.concat([df_class_0_under,df_class_1], axis=0)\n",
        "\n",
        "  return df_test_under\n",
        "\n",
        "\n",
        "def apply_tfidf(X_train, x_test):\n",
        "  # apply tfidf to lemma to create feature vector\n",
        "  ngram_range = (1,2)\n",
        "  max_features = 400 \n",
        "\n",
        "  tfidf = TfidfVectorizer(encoding='utf-8',\n",
        "                      ngram_range=ngram_range,\n",
        "                      max_features=max_features,\n",
        "                      min_df=1,\n",
        "                      max_df=1.0,\n",
        "                      norm='l2',\n",
        "                      sublinear_tf=True)\n",
        "  f_train = tfidf.fit_transform(X_train['lemma'])\n",
        "  f_test = tfidf.transform(x_test['lemma'])\n",
        "  feature_train = pd.DataFrame(f_train.toarray(), columns=tfidf.get_feature_names())\n",
        "\n",
        "  feature_test = pd.DataFrame(f_test.toarray(), columns=tfidf.get_feature_names())\n",
        "\n",
        "  feature_train.fillna(0.0,inplace=True)\n",
        "  feature_test.fillna(0.0, inplace=True)\n",
        "\n",
        "  return feature_train, feature_test                "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAYGaJPQPF9C"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def train_nb_model(feature_train, y_train, feature_test, y_test):\n",
        "\n",
        "  model = MultinomialNB()\n",
        "\n",
        "  model.fit(feature_train, y_train)\n",
        "\n",
        "\n",
        "  print(\"The bug testing metrics is: \")\n",
        "  print(\"accuracy \" + str(accuracy_score(y_test, model.predict(feature_test))))\n",
        "  print(\"f1 \" + str(f1_score(y_test, model.predict(feature_test))))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCe-VKCajBZi"
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "def train_svm_model(feature_train, y_train, feature_test, y_test):\n",
        "\n",
        "  C = [1,10]\n",
        "  gamma = [ 1, 10]\n",
        "  degree = [1, 2, 3]\n",
        "  kernel = [ 'linear','poly','rbf']\n",
        "  probability = [True]\n",
        "  random_grid = {'C': C,\n",
        "                'kernel': kernel,\n",
        "                'gamma': gamma,\n",
        "                'degree': degree,\n",
        "                'probability': probability\n",
        "               }\n",
        "  svc = svm.SVC(random_state=42)\n",
        "  # Definition of the random search\n",
        "  random_search = RandomizedSearchCV(estimator=svc,\n",
        "                                     param_distributions=random_grid,\n",
        "                                     n_iter=10,\n",
        "                                     scoring='balanced_accuracy',\n",
        "                                     cv=3,\n",
        "                                     verbose=1,\n",
        "                                     random_state=42)\n",
        "\n",
        "\n",
        "  random_search.fit(feature_train, y_train)\n",
        "  model = random_search.best_estimator_\n",
        "  print(random_search.best_params_)\n",
        "  model.fit(feature_train,y_train)\n",
        "\n",
        "  print(\"accuracy \" + str(accuracy_score(y_test, model.predict(feature_test))))\n",
        "  print(\"f1 \" + str(f1_score(y_test, model.predict(feature_test))))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7MsFZ8qPGtG",
        "outputId": "74748169-cdca-42c5-c299-eb35ac0effa1"
      },
      "source": [
        "# bug classifier data\n",
        "df = get_combined_df([\"Bug_tt.json\", \"Feature_tt.json\", \"Rating_tt.json\", \"UserExperience_tt.json\"],\n",
        "                     {\n",
        "                        'Bug': 1,\n",
        "                        'Not_Bug': 0,\n",
        "                        'Not_Feature': 0,\n",
        "                        'Feature': 0,\n",
        "                        'Rating': 0,\n",
        "                        'Not_Rating': 0,\n",
        "                        'UserExperience': 0,\n",
        "                        'Not_UserExperience': 0,\n",
        "                      })\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[['lemma']],\n",
        "                                                    df['label_code'],\n",
        "                                                    test_size=0.15,\n",
        "                                                    random_state=42)\n",
        "feature_train, feature_test = apply_tfidf(X_train, X_test)\n",
        "print(\"Bug classifier\")\n",
        "train_svm_model(feature_train, y_train, feature_test, y_test)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bug classifier\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   16.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'probability': True, 'kernel': 'rbf', 'gamma': 1, 'degree': 2, 'C': 1}\n",
            "accuracy 0.7522935779816514\n",
            "f1 0.7326732673267327\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i7BgfTQ0yqk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3f1d177-75e3-49e9-d93f-56b3d1fa4e54"
      },
      "source": [
        "# feature classifier data\n",
        "df = get_combined_df([\"Feature_tt.json\", \"Rating_tt.json\", \"UserExperience_tt.json\", \"Bug_tt.json\", ],\n",
        "                     {\n",
        "                        'Bug': 0,\n",
        "                        'Not_Bug': 0,\n",
        "                        'Not_Feature': 0,\n",
        "                        'Feature': 1,\n",
        "                        'Rating': 0,\n",
        "                        'Not_Rating': 0,\n",
        "                        'UserExperience': 0,\n",
        "                        'Not_UserExperience': 0,\n",
        "                      })\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[['lemma']],\n",
        "                                                    df['label_code'],\n",
        "                                                    test_size=0.15,\n",
        "                                                    random_state=42)\n",
        "feature_train, feature_test = apply_tfidf(X_train, X_test)\n",
        "print(\"Feature classifier\")\n",
        "train_svm_model(feature_train, y_train, feature_test, y_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature classifier\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   10.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'probability': True, 'kernel': 'linear', 'gamma': 1, 'degree': 3, 'C': 1}\n",
            "accuracy 0.7954545454545454\n",
            "f1 0.7954545454545455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teSfHiJ9JCqM",
        "outputId": "237236b4-26c0-4b16-a9ad-2c7d55c9a7ce"
      },
      "source": [
        "# rating classifier data\n",
        "df = get_combined_df([\"Rating_tt.json\", \"Bug_tt.json\", \"Feature_tt.json\",\"UserExperience_tt.json\"],\n",
        "                     {\n",
        "                        'Bug': 0,\n",
        "                        'Not_Bug': 0,\n",
        "                        'Not_Feature': 0,\n",
        "                        'Feature': 0,\n",
        "                        'Rating': 1,\n",
        "                        'Not_Rating': 0,\n",
        "                        'UserExperience': 0,\n",
        "                        'Not_UserExperience': 0,\n",
        "                      })\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[['lemma']],\n",
        "                                                    df['label_code'],\n",
        "                                                    test_size=0.15,\n",
        "                                                    random_state=42)\n",
        "feature_train, feature_test = apply_tfidf(X_train, X_test)\n",
        "print(\"Rating classifier\")\n",
        "train_svm_model(feature_train, y_train, feature_test, y_test)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rating classifier\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   17.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'probability': True, 'kernel': 'rbf', 'gamma': 1, 'degree': 2, 'C': 1}\n",
            "accuracy 0.6818181818181818\n",
            "f1 0.6534653465346534\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCIks5dQJDea",
        "outputId": "452778f2-74e7-4bcd-950d-17fd54a9fb64"
      },
      "source": [
        "# user experience classifier data\n",
        "df = get_combined_df([\"UserExperience_tt.json\", \"Bug_tt.json\", \"Feature_tt.json\",\"Rating_tt.json\"],\n",
        "                     {\n",
        "                        'Bug': 0,\n",
        "                        'Not_Bug': 0,\n",
        "                        'Not_Feature': 0,\n",
        "                        'Feature': 0,\n",
        "                        'Rating': 0,\n",
        "                        'Not_Rating': 0,\n",
        "                        'UserExperience': 1,\n",
        "                        'Not_UserExperience': 0,\n",
        "                      })\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[['lemma']],\n",
        "                                                    df['label_code'],\n",
        "                                                    test_size=0.15,\n",
        "                                                    random_state=42)\n",
        "feature_train, feature_test = apply_tfidf(X_train, X_test)\n",
        "print(\"UserExperience classifier\")\n",
        "train_svm_model(feature_train, y_train, feature_test, y_test)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UserExperience classifier\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   16.4s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'probability': True, 'kernel': 'rbf', 'gamma': 1, 'degree': 2, 'C': 1}\n",
            "accuracy 0.7706422018348624\n",
            "f1 0.761904761904762\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}